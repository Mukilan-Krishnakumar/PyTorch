{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7d4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bf07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Setting training device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b60df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char = re.compile(r'[;\\\\/,!.:*?\\\"<>|&\\']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905820ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey    Holla   \n"
     ]
    }
   ],
   "source": [
    "resp = re.sub(special_char, \" \", \"Hey,,,,Holla,.!\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703a586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562f60b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  split\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  train\n",
       "1   ham                      Ok lar... Joking wif u oni...  train\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  train\n",
       "3   ham  U dun say so early hor... U c already then say...  train\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  train"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"hamspam.csv\", index_col = [\"Unnamed: 0\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c292cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"v2\" : \"message\"}, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d30b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {}\n",
    "idx_to_token = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99738f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder(df, df_column):\n",
    "    uniq_values = df[df_column].unique()\n",
    "    number_of_features = len(uniq_values)\n",
    "    main_dict = {}\n",
    "    zero_list = np.zeros(len(df))\n",
    "    for num, val in enumerate(uniq_values):\n",
    "        # If you have main_dict[val] = zero_list, then you invariably create a reference and this would mess up the One Hot Encoding\n",
    "        main_dict[val] = list(zero_list)\n",
    "    for num, record in enumerate(df[df_column]):\n",
    "        main_dict[str(record)][num] = 1.0\n",
    "    df_one_hot = pd.DataFrame.from_dict(main_dict)\n",
    "    frames = [df, df_one_hot]\n",
    "    df_result = pd.concat(frames,axis=1, join='inner')\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7eb078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                            message  split  ham  spam\n",
      "0   ham  Go until jurong point, crazy.. Available only ...  train  1.0   0.0\n",
      "1   ham                      Ok lar... Joking wif u oni...  train  1.0   0.0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  train  0.0   1.0\n",
      "3   ham  U dun say so early hor... U c already then say...  train  1.0   0.0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...  train  1.0   0.0\n"
     ]
    }
   ],
   "source": [
    "df = OneHotEncoder(df, \"v1\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c423119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"v1\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7728bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f822dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/h29sqr1j4qlg8r6r10m9q9xh0000gn/T/ipykernel_54181/539089241.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([\"split\"], axis = 1 ,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop([\"split\"], axis = 1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405ee5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  ham  spam\n",
       "0  Go until jurong point, crazy.. Available only ...  1.0   0.0\n",
       "1                      Ok lar... Joking wif u oni...  1.0   0.0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  0.0   1.0\n",
       "3  U dun say so early hor... U c already then say...  1.0   0.0\n",
       "4  Nah I don't think he goes to usf, he lives aro...  1.0   0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44c2bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(np.stack(train_df[[\"ham\", \"spam\"]].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb32adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target = []\n",
    "\n",
    "for index, rows in train_df.iterrows():\n",
    "    if rows[\"ham\"] == 1.0:\n",
    "        a_target.append([0])\n",
    "    else:\n",
    "        a_target.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85db23e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_target = torch.Tensor(a_target).type(torch.LongTensor)\n",
    "a_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8910da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_target = a_target.flatten()\n",
    "a_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4571e098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3900])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fdafff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3900])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't run this, I am checking size\n",
    "output_vector = torch.zeros(len(train_df))\n",
    "output_vector.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c495495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3900, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f15b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(token):\n",
    "    if token in token_to_idx:\n",
    "        index = token_to_idx[token]\n",
    "    else:\n",
    "        index = len(token_to_idx)\n",
    "        token_to_idx[token] = index\n",
    "        idx_to_token[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13fe5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentences in df.message:\n",
    "    for word in sentences.split(\" \"):\n",
    "        word = re.sub(special_char, \" \", word)\n",
    "        word = word.lower()\n",
    "        add_token(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f00630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e684afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomVectorizer(message):\n",
    "    one_hot = torch.zeros(len(message), 1, len(token_to_idx))\n",
    "    for num, word in enumerate(message.split(\" \")):\n",
    "        word = re.sub(special_char, \" \", word)\n",
    "        word = word.lower()\n",
    "        if word in token_to_idx:\n",
    "            one_hot[num][0][token_to_idx[word]] = 1\n",
    "        else:\n",
    "            word = \"<UNK>\"\n",
    "            one_hot[num][0][token_to_idx[word]] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1103b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 1, 12461])\n"
     ]
    }
   ],
   "source": [
    "for sentence in df[\"message\"]:\n",
    "    print(CustomVectorizer(sentence).size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22504fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12460"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "820b03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size ,output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input_message, hidden):\n",
    "        combined = torch.cat((input_message, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6b7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(token_to_idx)\n",
    "hidden_size = len(token_to_idx)\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ebe83c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "input_text = train_df[\"message\"][0]\n",
    "print(len(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca3738db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "709a9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6891, -0.6973]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_text = CustomVectorizer(train_df[\"message\"][0])\n",
    "hidden = torch.zeros(1, hidden_size)\n",
    "output, next_hidden = rnn(input_text[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd217b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 1, 12461])\n"
     ]
    }
   ],
   "source": [
    "print(input_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c25159ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    class_i = top_i[0].item()\n",
    "    if class_i == 1:\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa557463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ham'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifyFromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10163ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12a3ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = train_df[:5]\n",
    "subset_target = a_target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cec721fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "def train(message_df, target):\n",
    "    hidden = rnn.initHidden()\n",
    "    range_df = len(message_df)\n",
    "    rnn.zero_grad()\n",
    "    output_vector  = torch.empty((0, 2), dtype = torch.float32)\n",
    "    for message_num in tqdm(range(range_df)):\n",
    "        vectorized_input = CustomVectorizer(message_df[\"message\"][message_num])\n",
    "        # Individual input processed by RNN\n",
    "        for i in range(vectorized_input.size()[0]):\n",
    "            output, hidden = rnn(vectorized_input[i],hidden)\n",
    "        output_vector = torch.cat((output_vector, output), 0)\n",
    "        \n",
    "    loss = criterion(output_vector, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "74168c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                          | 115/3900 [05:52<3:13:07,  3.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration Number :\u001b[39m\u001b[38;5;124m\"\u001b[39m,iteration)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;124m\"\u001b[39m, current_loss)\n",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(message_df, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Individual input processed by RNN\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vectorized_input\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m         output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorized_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output_vector, output), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_vector, target)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input_message, hidden)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_message, hidden):\n\u001b[1;32m     10\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((input_message, hidden), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi2h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2o(hidden)\n\u001b[1;32m     13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iters = 1\n",
    "\n",
    "for iteration in range(n_iters):\n",
    "    current_loss = 0\n",
    "    print(\"Iteration Number :\",iteration)\n",
    "    loss = train(train_df, a_target)\n",
    "    current_loss += loss\n",
    "    print(\"Loss \", current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f0672bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 10\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "403d1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itertion Number:  1\n",
      "Message Number:  0\n",
      "Output tensor([[-0.6777, -0.7089]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Target tensor([0])\n",
      "Loss tensor(0.6777, grad_fn=<NllLossBackward0>)\n",
      "Message Number:  1\n",
      "Output tensor([[-0.6736, -0.7131]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Target tensor([0])\n",
      "Loss tensor(0.6736, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# This will work -> target_value = torch.tensor([1])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     vectorized_input \u001b[38;5;241m=\u001b[39m CustomVectorizer(input_text)\n\u001b[0;32m----> 9\u001b[0m     output, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorized_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;124m\"\u001b[39m, current_loss)\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(vectorized_input, target_value)\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_value)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m rnn\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     17\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iter in range(1, n_iters + 1):\n",
    "    print(\"Itertion Number: \", iter)\n",
    "    current_loss = 0\n",
    "    for num, input_text in enumerate(train_df[\"message\"]):\n",
    "        print(\"Message Number: \", num)\n",
    "        target_value = a_target[num]\n",
    "        # This will work -> target_value = torch.tensor([1])\n",
    "        vectorized_input = CustomVectorizer(input_text)\n",
    "        output, loss = train(vectorized_input, target_value)\n",
    "        current_loss += loss\n",
    "    print(\"Loss \", current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d13e70d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6727, -0.7140]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_text = CustomVectorizer(\"hel, me, ewas\")\n",
    "hidden = torch.zeros(1, hidden_size)\n",
    "output, next_hidden = rnn(input_text[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acaeff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(input_text)):\n",
    "    output, hidden = rnn(input_text[i],hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e3a0ac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b26b7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message     target\n",
       "0  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  tensor(0)\n",
       "1  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...  tensor(0)\n",
       "2  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...  tensor(1)\n",
       "3  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...  tensor(0)\n",
       "4  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...  tensor(0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we put vectorized input and ham spam value as a Dataframe\n",
    "subset_df = pd.DataFrame(list(zip(vectorized_input, a_target)), columns = [\"message\", \"target\"])\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ecc48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = subset_df[\"message\"]\n",
    "labels = subset_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc876582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "078b9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3900/3900 [00:02<00:00, 1893.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# We did not batch anything, do that\n",
    "vectorized_input = []\n",
    "print(vectorized_input)\n",
    "for message in tqdm(train_df[\"message\"]):\n",
    "#     print(CustomVectorizer(message))\n",
    "#     vectorized_input = torch.cat((vectorized_input, CustomVectorizer(message)), 0)\n",
    "    vectorized_input.append(CustomVectorizer(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "04def6a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvectorized_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vectorized_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "361a2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "def train(message_df, target):\n",
    "    hidden = rnn.initHidden()\n",
    "    range_df = len(message_df)\n",
    "    rnn.zero_grad()\n",
    "    output_vector  = torch.empty((0, 2), dtype = torch.float32)\n",
    "    for message_num in tqdm(range(range_df)):\n",
    "        vectorized_input = message_df[message_num]\n",
    "        # Individual input processed by RNN\n",
    "        for i in range(vectorized_input.size()[0]):\n",
    "            output, hidden = rnn(vectorized_input[i],hidden)\n",
    "        output_vector = torch.cat((output_vector, output), 0)\n",
    "        \n",
    "    loss = criterion(output_vector, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "15f7ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                             | 12/3900 [00:50<4:30:12,  4.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration Number :\u001b[39m\u001b[38;5;124m\"\u001b[39m,iteration)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorized_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;124m\"\u001b[39m, current_loss)\n",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(message_df, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Individual input processed by RNN\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vectorized_input\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m         output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorized_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output_vector, output), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_vector, target)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input_message, hidden)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_message, hidden):\n\u001b[1;32m     10\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((input_message, hidden), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi2h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2o(hidden)\n\u001b[1;32m     13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iters = 1\n",
    "\n",
    "for iteration in range(n_iters):\n",
    "    current_loss = 0\n",
    "    print(\"Iteration Number :\",iteration)\n",
    "    loss = train(vectorized_input, a_target)\n",
    "    current_loss += loss\n",
    "    print(\"Loss \", current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f67c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    x_train = Variable(torch.from_numpy(features)).float()\n",
    "    y_train = Variable(torch.from_numpy(labels)).long()\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        print (\"epoch #\",epoch)\n",
    "        print (\"loss: \", loss.item())\n",
    "        pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "        print (\"acc:(%) \", 100*pred/len(x_train))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4e093b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5e6991b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Series)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [120]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(epochs):\n\u001b[0;32m----> 2\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m Variable(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      3\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(labels))\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Series)"
     ]
    }
   ],
   "source": [
    "train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4612a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
