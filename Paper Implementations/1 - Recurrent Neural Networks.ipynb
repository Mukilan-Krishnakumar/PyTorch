{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd2fd83",
   "metadata": {},
   "source": [
    "# Building a Recurrent Neural Network from Scratch\n",
    "\n",
    "We will be using the Ham Spam Dataset to train a neural network which can classify messages as spam or ham. \n",
    "\n",
    "The Gameplan:\n",
    "1. Dataset \n",
    "2. DataLoader\n",
    "3. Building RNN\n",
    "4. Training Loop\n",
    "5. Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2000005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c84b8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa7f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hamspam.csv\", index_col = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f20451d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  split\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  train\n",
       "1   ham                      Ok lar... Joking wif u oni...  train\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  train\n",
       "3   ham  U dun say so early hor... U c already then say...  train\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad46f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"target\", \"message\", \"split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52e6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dict = {\"ham\": 0, \"spam\": 1}\n",
    "def conversion_fn(target_val):\n",
    "    return conversion_dict[target_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf1cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"target\"].map(lambda x: conversion_fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b73b2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                            message  split\n",
       "0       0  Go until jurong point, crazy.. Available only ...  train\n",
       "1       0                      Ok lar... Joking wif u oni...  train\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...  train\n",
       "3       0  U dun say so early hor... U c already then say...  train\n",
       "4       0  Nah I don't think he goes to usf, he lives aro...  train"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa3c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, messages):\n",
    "        self.token_to_idx = {}\n",
    "        self.idx_to_token = {}\n",
    "        self.messages = messages\n",
    "        self.add_token(\"<UNK>\")\n",
    "        self.special_char = re.compile(r'[;\\\\/,!.:*?\\\"<>|&\\']')\n",
    "        for message in messages:\n",
    "            for word in message.split(\" \"):\n",
    "                word = re.sub(self.special_char, \" \", word)\n",
    "                word = word.lower()\n",
    "                self.add_token(word)\n",
    "        \n",
    "    def add_token(self,token):\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "            \n",
    "    def vectorize(self, message):\n",
    "        one_hot = torch.zeros(len(self.token_to_idx))\n",
    "        for num, word in enumerate(message.split(\" \")):\n",
    "            word = re.sub(self.special_char, \" \", word)\n",
    "            word = word.lower()\n",
    "            if word in self.token_to_idx:\n",
    "                one_hot[self.token_to_idx[word]] = 1\n",
    "            else:\n",
    "                word = \"<UNK>\"\n",
    "                one_hot[self.token_to_idx[word]] = 1\n",
    "        return one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda4725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a2ddc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, df, messages_col, target_col, transform = None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.messages = self.df[messages_col]\n",
    "        self.target = self.df[target_col]\n",
    "        \n",
    "        self.vocab = Vocabulary(self.messages)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        message = self.messages[index]\n",
    "        target = self.target[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            message = self.transform(message)\n",
    "            \n",
    "        vectorized_message = torch.tensor(self.vocab.vectorize(message))\n",
    "        vectorized_target = torch.tensor(target)\n",
    "        \n",
    "        return vectorized_message, vectorized_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4841eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(df, \"message\", \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c87419df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/h29sqr1j4qlg8r6r10m9q9xh0000gn/T/ipykernel_1216/3678166653.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vectorized_message = torch.tensor(self.vocab.vectorize(message))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor(0))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eb1794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8d7a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size ,output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input_message, hidden):\n",
    "        combined = torch.cat((input_message, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6d231a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad4bd285",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_to_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtoken_to_idx\u001b[49m)\n\u001b[1;32m      2\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(token_to_idx)\n\u001b[1;32m      3\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_to_idx' is not defined"
     ]
    }
   ],
   "source": [
    "input_size = len(token_to_idx)\n",
    "hidden_size = len(token_to_idx)\n",
    "output_size = 2\n",
    "model = RNN(input_size, hidden_size, output_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af2162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
