{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7d4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bf07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Setting training device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b60df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char = re.compile(r'[;\\\\/,!.:*?\\\"<>|&\\']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905820ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey    Holla   \n"
     ]
    }
   ],
   "source": [
    "resp = re.sub(special_char, \" \", \"Hey,,,,Holla,.!\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703a586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562f60b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  split\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  train\n",
       "1   ham                      Ok lar... Joking wif u oni...  train\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  train\n",
       "3   ham  U dun say so early hor... U c already then say...  train\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  train"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"hamspam.csv\", index_col = [\"Unnamed: 0\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c292cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"v2\" : \"message\"}, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d30b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {}\n",
    "idx_to_token = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99738f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder(df, df_column):\n",
    "    uniq_values = df[df_column].unique()\n",
    "    number_of_features = len(uniq_values)\n",
    "    main_dict = {}\n",
    "    for num, val in enumerate(uniq_values):\n",
    "        # If you have main_dict[val] = zero_list, then you invariably create a reference and this would mess up the One Hot Encoding\n",
    "        main_dict[val] = list(zero_list)\n",
    "    for num, record in enumerate(df[df_column]):\n",
    "        main_dict[str(record)][num] = 1.0\n",
    "    df_one_hot = pd.DataFrame.from_dict(main_dict)\n",
    "    frames = [df, df_one_hot]\n",
    "    df_result = pd.concat(frames,axis=1, join='inner')\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7eb078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                            message  split  ham  spam\n",
      "0   ham  Go until jurong point, crazy.. Available only ...  train  1.0   0.0\n",
      "1   ham                      Ok lar... Joking wif u oni...  train  1.0   0.0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  train  0.0   1.0\n",
      "3   ham  U dun say so early hor... U c already then say...  train  1.0   0.0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...  train  1.0   0.0\n"
     ]
    }
   ],
   "source": [
    "df = OneHotEncoder(df, \"v1\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c423119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"v1\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7728bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f822dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/h29sqr1j4qlg8r6r10m9q9xh0000gn/T/ipykernel_924/539089241.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([\"split\"], axis = 1 ,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop([\"split\"], axis = 1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405ee5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  ham  spam\n",
       "0  Go until jurong point, crazy.. Available only ...  1.0   0.0\n",
       "1                      Ok lar... Joking wif u oni...  1.0   0.0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  0.0   1.0\n",
       "3  U dun say so early hor... U c already then say...  1.0   0.0\n",
       "4  Nah I don't think he goes to usf, he lives aro...  1.0   0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44c2bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(np.stack(train_df[[\"ham\", \"spam\"]].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cb32adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target = []\n",
    "\n",
    "for index, rows in train_df.iterrows():\n",
    "    if rows[\"ham\"] == 1.0:\n",
    "        a_target.append([0])\n",
    "    else:\n",
    "        a_target.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "85db23e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_target = torch.Tensor(a_target).type(torch.LongTensor)\n",
    "a_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c495495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3900, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f15b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(token):\n",
    "    if token in token_to_idx:\n",
    "        index = token_to_idx[token]\n",
    "    else:\n",
    "        index = len(token_to_idx)\n",
    "        token_to_idx[token] = index\n",
    "        idx_to_token[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fe5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentences in df.message:\n",
    "    for word in sentences.split(\" \"):\n",
    "        word = re.sub(special_char, \" \", word)\n",
    "        word = word.lower()\n",
    "        add_token(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f00630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e684afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomVectorizer(message):\n",
    "    one_hot = torch.zeros(len(message), 1, len(token_to_idx))\n",
    "    for num, word in enumerate(message.split(\" \")):\n",
    "        word = re.sub(special_char, \" \", word)\n",
    "        word = word.lower()\n",
    "        if word in token_to_idx:\n",
    "            one_hot[num][0][token_to_idx[word]] = 1\n",
    "        else:\n",
    "            word = \"<UNK>\"\n",
    "            one_hot[num][0][token_to_idx[word]] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1103b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 1, 12461])\n"
     ]
    }
   ],
   "source": [
    "for sentence in df[\"message\"]:\n",
    "    print(CustomVectorizer(sentence).size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22504fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12460"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "820b03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size ,output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input_message, hidden):\n",
    "        combined = torch.cat((input_message, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd6b7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(token_to_idx)\n",
    "hidden_size = len(token_to_idx)\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ebe83c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "input_text = train_df[\"message\"][0]\n",
    "print(len(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca3738db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "709a9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6852, -0.7011]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_text = CustomVectorizer(train_df[\"message\"][0])\n",
    "hidden = torch.zeros(1, hidden_size)\n",
    "output, next_hidden = rnn(input_text[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd217b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 1, 12461])\n"
     ]
    }
   ],
   "source": [
    "print(input_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c25159ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    class_i = top_i[0].item()\n",
    "    if class_i == 1:\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa557463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifyFromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10163ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cec721fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "# Should send vectorized output as input to this function\n",
    "def train(vectorized_input, target_value):\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(vectorized_input.size()[0]):\n",
    "        output, hidden = rnn(vectorized_input[i],hidden)\n",
    "    \n",
    "    loss = criterion(output, target_value)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f0672bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 10\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "403d1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itertion Number:  1\n",
      "Message Number:  0\n",
      "tensor([[-0.6859, -0.7005]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  1\n",
      "tensor([[-0.6818, -0.7047]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  2\n",
      "tensor([[-0.6777, -0.7089]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([1])\n",
      "Message Number:  3\n",
      "tensor([[-0.6819, -0.7045]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  4\n",
      "tensor([[-0.6778, -0.7087]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  5\n",
      "tensor([[-0.6737, -0.7129]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([1])\n",
      "Message Number:  6\n",
      "tensor([[-0.6779, -0.7086]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  7\n",
      "tensor([[-0.6739, -0.7128]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([0])\n",
      "Message Number:  8\n",
      "tensor([[-0.6699, -0.7170]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# This will work -> target_value = torch.tensor([1])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     vectorized_input \u001b[38;5;241m=\u001b[39m CustomVectorizer(input_text)\n\u001b[0;32m----> 9\u001b[0m     output, loss \u001b[38;5;241m=\u001b[39m train(vectorized_input, target_value)\n\u001b[1;32m     10\u001b[0m     current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;124m\"\u001b[39m, current_loss)\n",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(vectorized_input, target_value)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_value)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_value)\n\u001b[0;32m---> 14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m rnn\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     17\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/CV/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/CV/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iter in range(1, n_iters + 1):\n",
    "    print(\"Itertion Number: \", iter)\n",
    "    current_loss = 0\n",
    "    for num, input_text in enumerate(train_df[\"message\"]):\n",
    "        print(\"Message Number: \", num)\n",
    "        target_value = a_target[num]\n",
    "        # This will work -> target_value = torch.tensor([1])\n",
    "        vectorized_input = CustomVectorizer(input_text)\n",
    "        output, loss = train(vectorized_input, target_value)\n",
    "        current_loss += loss\n",
    "    print(\"Loss \", current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e70d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
